% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pmoe.R
\name{pmoe}
\alias{pmoe}
\alias{pmoe.default}
\alias{pmoe.formula}
\title{Penalized Mixtures of Experts}
\usage{
pmoe(X, ...)

\method{pmoe}{formula}(formula, data, subset, na.action, ...)

\method{pmoe}{default}(X, y, colsGating = 1:ncol(X),
  colsExperts = 1:ncol(X), interceptGating = TRUE,
  interceptExperts = TRUE, offsetGating = NULL, offsetExperts = NULL,
  J = 2, lambda, alpha = 1, penalty = c("ungrouped", "grouped"),
  type.multinomial = c("ungrouped", "grouped"), model = c("binomial",
  "multinomial"), standardize = FALSE, genetic = FALSE,
  ipopt.max.iter = 500, ipopt.tol = 1e-06, ...)
}
\arguments{
\item{X}{(Required if no \code{formula} is given as principal argument.) A \code{matrix} or \code{data.frame} or \code{Matrix} containing
the explanatory variables (must not contain an intercept column).}

\item{formula}{A \code{formula} with two right-hand sides of the form \code{y ~ expert model | gating model}.
The normal formula syntax applies (see \code{\link[Formula]{Formula}}).
In order to use all available columns one or both right-hand sides can be dots (\code{y ~ . | .}, \code{y ~ . | gating model}).
Both right-hand sides normally contain an intercept (which is not penalized) that can be removed by adding \code{0} or \code{- 1}.
Offsets are allowed, too.
The left-hand side should be a vector indicating the class membership, preferably a \code{factor}.}

\item{data}{A \code{data.frame} from which variables specified in \code{formula} are to be taken.}

\item{subset}{A subset...}

\item{na.action}{...}

\item{y}{(Required if no \code{formula} is given as principal argument.) A \code{factor} specifying
the class membership for each observation.}

\item{colsGating}{Names or indices of columns in \code{X} to be used for the gating model. Default is all columns.}

\item{colsExperts}{Names or indices of columns in \code{X} to be used for the expert models. Default is all columns.}

\item{interceptGating}{Logical. Does the gating model include an intercept? If \code{TRUE}, an intercept column is added to \code{X}.
Defaults to \code{TRUE}.}

\item{interceptExperts}{Logical. Does the expert model include an intercept? If \code{TRUE}, an intercept column is added to \code{X}.
Defaults to \code{TRUE}.}

\item{offsetGating}{Offset term for the gating model.}

\item{offsetExperts}{Offset term for the expert model.}

\item{J}{The number of experts / mixture components. Defaults to 2.}

\item{lambda}{Penalty parameter. Can be a scalar or a vector of length \code{1+J} with different components for the gating and the
\code{J} expert models. All components must be >= 0.}

\item{alpha}{Mixing parameter for the elastic net penalty. Can be a scalar or a vector of length \code{1+J} with different components
for the gating and the \code{J} expert models. All components must be in [0,1].
Defaults to 1.}

\item{penalty}{...}

\item{type.multinomial}{\code{"grouped"}, \code{"ungrouped"}.}

\item{model}{...}

\item{standardize}{Logical. Should the columns of \code{X} be standardized prior to fitting the model?
Defaults to \code{FALSE}. If \code{TRUE} the coefficients are returned on the original scale.}

\item{genetic}{Logical.}

\item{ipopt.max.iter}{The maximum number of IPOPT iterations.}

\item{ipopt.tol}{Tolerance for IPOPT convergence.}

\item{\dots}{Further arguments.}
}
\value{
An object of class \code{pmoe}.
}
\description{
Train a penalized mixture of experts model by IPOPT.
}
\references{
Waechter, A. and Biegler, L. T. (2006),
On the Implementation of an Interior-Point Filter Line-Search Algorithm for Large-Scale Nonlinear Programming,
\emph{Mathematical Programming}, \strong{106}, 25-57.
}

